title: Can Sora understand 3D?
date: Febrary 26, 2024
author: Hwan Heo
--- 여기부터 실제 콘텐츠 ---

<button id="copyButton">
    <i class="bi bi-share-fill"></i>
</button>

<div id="myshare_modal" class="share_modal">
    <div class="share_modal-content">
        <span class="share_modal_close">×</span>
        <p><strong>Link Copied!</strong></p>
        <div class="copy_indicator-container">
        <div class="copy_indicator" id="share_modalIndicator"></div>
        </div>
    </div>
</div>

<nav class="toc">
    <ul>
        <li>
            <a href="#intro"> Introduction</a>
        </li>
        <ul>
            <li>
                <a href="#sora"> Can Sora understand 3D? </a>
            </li>
        </ul>
        <li><a href="#experiments"> Experiments </a></li>
        <ul>
            <li>
                <a href="#set"> SfM from Sora </a>
            </li>
            <li>
                <a href="#nerf"> NeRF from Sora </a>
            </li>
            <li>
                <a href="#gs"> Gaussian Splatting from Sora </a>
            </li>
        </ul>
        <li><a href="#conclusion"> Closing </a></li>
    </ul>
</nav>


<br/>
<h2 id="tl-dr">TL; DR</h2>
<figure>
    <img src="./240226_sora/assets/image.gif" alt="Gaussian RT" width="100%">
    <figcaption style="text-align: center; font-size: 15px;"><strong></strong> NeRF Reconstruction from SORA </figcaption>
</figure>
<p>In this article, I will explore the capabilities of 3D reconstruction through Neural Rendering techniques (NeRF and 3D Gaussian Splatting) by analyzing a video generated by OpenAI’s recently released Video Generation AI, <a href="https://openai.com/sora">Sora</a>.</p> 
<p> The goal of the project includes examining the geometric consistency of Sora’s output and reflecting on the implications for the future of AI in video generation.</p>

<h2 id="intro">Introduction</h2>
<p>Sora represents a groundbreaking development in AI, comparable to the impact of ChatGPT. While overcoming the curse of dimensionality in machine learning is notoriously challenging, I initially believed it would take a significant amount of time for video generation models to achieve performance levels similar to those seen in 2D image diffusion models.</p>
<p>However, a study from early 2024 has proven this assumption wrong. The following video provides a glimpse of Sora&#39;s remarkable capabilities:</p>
<div class="video-container">
    <iframe width="100%" src="https://www.youtube.com/embed/HK6y8DAPN_0?si=86HWbOrGACbYvlEe&amp;start=82" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>
<p>This video showcases a substantial improvement over previous video generation models, which often struggled to maintain consistency even between frames. The smoothness and continuity in Sora&#39;s output indicate a new level of sophistication in video generation.</p>

<h3 id="sora">Can Sora understand 3D?</h3>
<p>Given my background in 3D reconstruction, I became curious about whether Sora generates scenes with an understanding of geometric consistency or merely maintains content consistency. To explore this, I formulated the following hypothesis:</p>
<ul>
<li><strong>Hypothesis:</strong> If Sora demonstrates a robust understanding of 3D geometry, then its generated outputs should facilitate accurate 3D reconstruction using computer vision techniques.</li>
</ul>
<p>To test this hypothesis, I adopted a method similar to Novel View Synthesis from real-world capture, which involves:</p>
<ol>
<li>Capturing the video.</li>
<li>Camera pose tracking (calibrating extrinsic and intrinsic parameters).</li>
<li>NeRF Training for 3D reconstruction.</li>
</ol>
<br/>

<h2 id="experiments">Experiments</h2><br/>
<p>I selected four videos from Sora’s published examples as candidates for 3D reconstruction:</p>
<table>
    <tr>
        <th> Big Sur </th>
        <th> Santorini </th>
    </tr>
    <tr>
        <td><video controls style="width: 100%;"><source src="https://cdn.openai.com/sora/videos/big-sur.mp4" type="video/mp4"></video></td>
        <td><video controls style="width: 100%;"><source src="https://cdn.openai.com/sora/videos/santorini.mp4" type="video/mp4"></video></td>
    </tr>
    <tr>
        <th> Art Museum </th>
        <th> Gold Rush </th>
    </tr>
    <tr>
        <td><video controls style="width: 100%;"><source src="https://cdn.openai.com/sora/videos/art-museum.mp4" type="video/mp4"></video></td>
        <td><video controls style="width: 100%;"><source src="https://cdn.openai.com/sora/videos/gold-rush.mp4" type="video/mp4"></video></td>
    </tr>
</table>
<p>These scenes were chosen based on their relatively static nature, as scenes with too many dynamic objects would complicate reconstruction.</p>
<h3 id="cam"> Structure-from-Motion from Sora </h3>
<p>After downloading the videos, I sampled the frames and performed Structure from Motion (SfM) using COLMAP. This process allowed us to assess how well Sora&#39;s output aligns with 3D geometry as assumed by stereo vision.</p>
<p><em>COLMAP is a computer vision tool that identifies image features (such as edges), performs feature matching, and utilizes bundle adjustment to determine the spatial positions of each frame.</em></p>
<p>The COLMAP results are as follows:</p>
<ol>
<li><p><strong>Santorini </strong></p>
    <figure>
        <img src="./240226_sora/assets/image.gif" alt="Gaussian RT" width="100%">
        <figcaption style="text-align: center; font-size: 15px;">COLMAP reconstruction from Sora: Santorini </figcaption>
    </figure>
</li>
<li><p><strong>Museum </strong></p>
    <figure>
        <img src="./240226_sora/assets/image.gif" alt="Gaussian RT" width="100%">
        <figcaption style="text-align: center; font-size: 15px;">COLMAP reconstruction from Sora: Museum </figcaption>
    </figure>
</li>
</ol>
<p>In both cases, camera pose alignment was achieved to some extent. However, the results suggest that Sora does not fully comprehend 3D geometry. It appears to stretch existing landscapes to maintain content consistency rather than accurately represent 3D structures, as seen in the museum scene where the rectangular space is not properly reconstructed.</p>
<p>Compared to previous video generation methods that struggled with even content consistency, Sora shows enough geometric consistency to allow for convergence below a certain error threshold during bundle adjustment, which relies on stereo vision (epipolar geometry). It is also noteworthy that the COLMAP process took longer than usual, likely due to the time required to align features that do not perfectly match in 3D.</p>
<h3 id="nerf"> NeRF Reconstruction</h3>
<p>Using the camera poses obtained from COLMAP, I proceeded with NeRF reconstruction. The results indicate that NeRF can successfully reconstruct the view for the visible portions of the scene.</p>
<ol>
    <li><p><strong>Big Sur</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/h4QMYO-c2nQ?si=Nq4-7w4zsX6rPFmU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
    <li><p><strong>Santorini</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/kqkii-L0q9M?si=-GUisg8x9rucU43g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
    <li><p><strong>Museum</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/ZK-f_hW655c?si=fakRiEz9eL8OURGY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
    <li><p><strong>GoldRush</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/Qmc971VRdQM?si=LHsY8n0juvRw-_oC" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
</ol>
<br/>

<h3 id="gs"> 3D Gaussian Splatting Reconstruction</h3>
<p>In addition to NeRF, I performed 3D reconstruction using 3D Gaussian Splatting (GS) based on the COLMAP sparse point cloud.</p>
<ul>
<li>3D GS is characterized by lower reconstruction quality in scenes with image distortion or misalignment compared to NeRF. This is because, unlike NeRF, which can learn to smooth out misaligned images due to the inherent smoothness of MLP (Multi-Layer Perceptron), 3D GS is an <strong>explicit method</strong> that does not offer this capability.</li>
</ul>
<p>Thus, the results from 3D GS provide additional insight into Sora’s ability to understand 3D geometry beyond what is visible with COLMAP and NeRF alone.</p>
<ol>
    <li><p><strong>Big Sur</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/H4n7T8mWMEo?si=nRPvzDjDeCe1kRWI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
    <li><p><strong>Santorini</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/MfrZZO-eRNg?si=ZTO913ZS7Nsc20NH" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
    <li><p><strong>Museum</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/-2AZSHDYwTk?si=hgV6U76xGdPTPCqn" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
    <li><p><strong>GoldRush</strong></p>
        <div class="video-container">
            <iframe width="100%" src="https://www.youtube.com/embed/n_rZVhs9OBU?si=YPqL8ExksLYqdsG3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </li>
</ol>
<p>While the qualitative quality between NeRF and 3D GS does not differ significantly, there are notable discrepancies in the Santorini scene, where the geometry is significantly off. Additionally, individual splats become visible when zooming into scenes reconstructed with splats.</p>

<h2 id="conclusion">Closing</h2>
<p>
    In summary, Neural Reconstruction from Sora shows
</p>
<ol>
<li><strong>Geometric Consistency</strong><br/>Sora still lacks full geometric consistency (3D) in its generated outputs.</li><br/>
<li><strong>SfM Performance</strong><br/>Despite this, SfM is sufficiently consistent to operate effectively.</li><br/>
<li><strong>Human Perception</strong><br/>Neither Sora&#39;s nor NeRF/3D GS&#39;s outputs appear particularly strange when viewed normally. This may be because humans focus more on the content within and between scenes rather than attempting to form a perfect 3D geometric understanding.</li><br/>
<li><strong>Future Potential</strong><br/>If video generation can consistently maintain content consistency, I believe geometric consistency will eventually be resolved. This is because real-world 3D shapes tend to be efficient and familiar.</li>
</ol>
<p>Given that this is just the first generation of Sora, its current performance is impressive. I am optimistic that within one or two more generations, models like Sora could generate videos that can be seamlessly reconstructed through neural rendering technologies for use in applications such as gaming. As a researcher, it is both exciting and humbling to witness such rapid progress, and I will be closely following OpenAI&#39;s advancements.</p>
<hr/>
<p>
    You may also like, 
</p>
<ul>
    <li>
        <a href="./?id=240805_gs/">
            <span style="text-decoration: underline;">A Comprehensive Analysis of Gaussian Splatting Rasterization</span>
        </a>
    </li>
    <li>
        <a href="./?id=240602_2dgs/">
            <span style="text-decoration: underline;">Under the 3D: Geometrically Accurate 2D Gaussian Splatting </span>
        </a>
    </li>
</ul>
<br/>